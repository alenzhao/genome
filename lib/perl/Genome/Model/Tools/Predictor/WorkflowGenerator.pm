package Genome::Model::Tools::Predictor::WorkflowGenerator;

use strict;
use warnings;
use Genome;

use lib '/gsc/scripts/opt/bacterial-bioperl';

class Genome::Model::Tools::Predictor::WorkflowGenerator {
    is => 'Command::V2',
    attributes_have => [
        workflow_input => {
            is => 'Boolean',
            default_value => 0,
            doc => 'Flags a property as being a direct input to the workflow',
        },
        workflow_output => {
            is => 'Boolean',
            default_value => 0,
            doc => 'Flags a property as being a direct output of the workflow',
        },
    ],
    has => [
        strategy => {
            is => 'Text',
            is_input => 1,
            doc => 'String to be parsed and turned into a workflow consisting of predictors',
        },
        gram_stain => {
            is => 'Text',
            is_input => 1,
            workflow_input => 1,
            is_optional => 1,
        },
        workflow_name => {
            is => 'Text',
            is_input => 1,
            is_optional => 1,
            default => 'prediction workflow',
            doc => 'Name to be given to generated workflow',
        },
        output_directory => {
            is => 'DirectoryPath',
            is_input => 1,
            workflow_input => 1,
            doc => 'Base directory in which all output is placed',
        },
        chunk_size => {
            is => 'Number',
            is_input => 1,
            workflow_input => 1,
            doc => 'Number of sequences to be included in each fasta chunk, if splitting is necessary',
        },
        input_fasta_file => {
            is => 'FilePath',
            is_input => 1,
            workflow_input => 1,
            doc => 'Path to fasta file containing sequence that predictors should run on',
        },
        dump_predictions_to_file => {
            is => 'Boolean',
            is_input => 1,
            is_optional => 1,
            workflow_input => 1,
            default_value => 0,
            doc => 'If set, predictions get dumped to a file',
        },
        dump_workflow_xml_file => {
            is => 'Boolean',
            is_input => 1,
            is_optional => 1,
            default_value => 0,
            doc => 'If set, a workflow xml file is dumped in the output directory',
        },
        run_inline => {
            is => 'Boolean',
            is_input => 1,
            is_optional => 1,
            default_value => 0,
            doc => 'If set, the workflow is run inline on the current host without any LSF job submissions',
        },
        bio_seq_features => {
            is => 'ARRAY',
            is_many => 1,
            is_output => 1,
            doc => 'List of bio seq features generated by prediction workflow',
        },
    ],
    has_transient_optional => [
        _parser => {
            is => 'Genome::Model::Tools::Predictor::StrategyParser',
        },
        _workflow => {
            is => 'Genome::WorkflowBuilder::DAG',
        },
        _result => {
            is => 'HASH',
            doc => 'Result returned from running workflow',
        },
    ],
    doc => 'can create and execute a prediction workflow',
};

sub execute {
    my $self = shift;
    unless ($self->start) {
        die "No result from executing workflow!";
    }
    return 1;
}

sub start {
    my $self = shift;
    unless ($self->_result) {
        my $workflow = $self->workflow;
        $self->debug_message("Generated workflow successfully!");

        my %inputs = $self->gather_inputs;
        $self->debug_message("Gathered inputs, now executing workflow!");

        my $result;
        if ($self->run_inline) {
            $result = $workflow->execute_inline(\%inputs);
        }
        else {
            $result = $workflow->execute(inputs => \%inputs);
        }
        unless ($result) {
            die "Error running prediction workflow";
        }

        $self->_result($result);
        $self->bio_seq_features($result->{bio_seq_features});
        $self->debug_message("Workflow complete, generated " . scalar $self->bio_seq_features . " Bio::SeqFeature objects!");
    }

    return $self->_result;
}

sub gather_inputs {
    my $self = shift;
    my $parser = $self->_get_or_create_parser();
    my %result = %{$parser->get_result};

    my @property_names = map { $_->property_name } 
        Genome::Model::Tools::Predictor::Base->__meta__->properties(predictor_specific => 1);

    # Add predictor specific inputs that were parsed from the strategy
    my %inputs;
    for my $predictor (sort keys %result) {
        for my $property (@property_names) {
            if (exists $result{$predictor}{$property}) {
                $inputs{$predictor . '_' . $property} = $result{$predictor}{$property};
            }
        }
    }

    # Special handling for output directory
    for my $predictor (sort keys %result) {
        $inputs{$predictor . '_output_directory'} = join('/', $self->output_directory, $predictor);
    }

    # Add workflow inputs that aren't specific to any predictor
    my @workflow_inputs = map { $_->property_name } 
        $self->__meta__->properties(workflow_input => 1);
    for my $workflow_input (@workflow_inputs) {
        $inputs{$workflow_input} = $self->$workflow_input;
    }

    return %inputs;
}

sub workflow {
    my $self = shift;
    return $self->generate_workflow;
}

# Generates a workflow object that includes all the predictors specified in the strategy. The
# workflow is then validated and returned.
sub generate_workflow {
    my $self = shift;
    return $self->_workflow if $self->_workflow;

    my $parser = $self->_get_or_create_parser();

    # Create workflow object
    my %input_mapping = $self->_gather_properties_of_type('input');
    my %output_mapping = $self->_gather_properties_of_type('output');
    my @inputs = $self->_get_unique_values(%input_mapping);
    my @outputs = $self->_get_unique_values(%output_mapping);

    my $workflow = Genome::WorkflowBuilder::DAG->create(
        name => $self->workflow_name,
    );

    # Create fasta chunking operation, if necessary
    my $fasta_chunk_operation = $self->_make_fasta_chunk_operation($workflow);

    # Create predictor operations
    my @predictor_operations = $self->_make_predictor_operations($workflow);

    # Link predictors to input connector and possibly fasta chunker
    $self->_link_inputs_to_predictors(
        workflow => $workflow,
        predictor_operations => \@predictor_operations,
        fasta_chunk_operation => $fasta_chunk_operation,
    );

    # Create the converge step and link predictors to it
    my $converge_operation = $self->_create_converge_and_link_to_predictors(
        workflow => $workflow,
        predictor_operations => \@predictor_operations,
    );

    # Create ace file merge step, link predictors to it
    my $merge_ace_file_operation = $self->_create_merge_ace_file_operation(
        workflow => $workflow,
        predictor_operations => \@predictor_operations,
    );

    # Validate and return
    my @errors = $workflow->validate;
    if (@errors) {
        die "Could not validate workflow:\n" . join("\n", @errors);
    }

    if ($self->dump_workflow_xml_file) {
        my $xml = $workflow->get_xml;
        my $xml_fh = Genome::Sys->write_file($self->workflow_xml_file_path, $xml);
    }

    unless (-d $self->log_directory) {
        Genome::Sys->create_directory($self->log_directory);
    }
    $workflow->recursively_set_log_dir($self->log_directory);

    $self->_workflow($workflow);
    return $self->_workflow;
}

sub workflow_xml_file_path {
    my $self = shift;
    return join('/', $self->output_directory, 'workflow.xml');
}

sub log_directory {
    my $self = shift;
    return join('/', $self->output_directory, 'logs');
}

# Collects properties of a particular type (right now, inputs and outputs) from specified
# predictors and those property that have been flagged as workflow specific. Those properties
# are put into a hash grouped by either predictor or into an "other" bin.
sub _gather_properties_of_type {
    my ($self, $type) = @_;
    unless (grep { $type eq $_ } qw/ input output/) {
        die "Invalid type $type passed to gather_properties_of_type!";
    }

    unless ($self->{$type . '_mapping'}) {
        my $property_type = "is_" . $type;
        my $workflow_type = "workflow_" . $type;

        my $meta = Genome::Model::Tools::Predictor::Base->__meta__;
        my @generics;
        my @predictor_specific;
        for my $property ($meta->properties($property_type => 1)) {
            if ($property->can('predictor_specific') and $property->predictor_specific) {
                push @predictor_specific, $property->property_name;
            }
            else {
                push @generics, $property->property_name;
            }
        }

        my @predictors = $self->_get_or_create_parser->predictor_classes;
        my %mapping;
        for my $predictor (@predictors) {
            my $short_name = $predictor->class_to_short_name;
            for my $predictor_specific (@predictor_specific) {
                push @{$mapping{$predictor}}, ($short_name . '_' . $predictor_specific);
            }
            push @{$mapping{$predictor}}, @generics;
        }

        $mapping{other} = [map { $_->property_name } $self->__meta__->properties($workflow_type => 1)];

        $self->{$type . '_mapping'} = \%mapping;
    }

    return %{$self->{$type . '_mapping'}};
}

# Either gets a previously created parser or makes a new one
sub _get_or_create_parser {
    my $self = shift;
    unless ($self->_parser) {
        my $parser = Genome::Model::Tools::Predictor::StrategyParser->create(strategy => $self->strategy);
        $self->_parser($parser);
    }
    return $self->_parser;
}

# Gets unique inputs/outputs from the hash generated by gather_properties_of_type
sub _get_unique_values { 
    my $self = shift;
    my %hash = @_;
    my %unique;
    for my $key (keys %hash) {
        my @values = @{$hash{$key}};
        for my $value (@values) {
            $unique{$value}++;
        }
    }
    return keys %unique;
}

# Make the fasta chunking operation if any of the predictors require chunking. Links between
# input connector and chunk operation are also made.
sub _make_fasta_chunk_operation {
    my ($self, $workflow) = @_;
    my @predictors = $self->_get_or_create_parser->predictor_classes;

    my $fasta_chunk_operation;
    if (grep { $_->requires_chunking } @predictors) {
        $fasta_chunk_operation = Genome::WorkflowBuilder::Command->create(
            name => 'chunk fasta sequences',
            command => 'Genome::Model::Tools::Predictor::FastaChunker',
        );
        $workflow->add_operation($fasta_chunk_operation);

        for my $property (qw(chunk_size input_fasta_file)) {
            $workflow->connect_input(
                input_property => $property,
                destination => $fasta_chunk_operation,
                destination_property => $property,
            );
        }
    }

    return $fasta_chunk_operation;
}

# Makes all the operations for the predictors, but doesn't link them to anything.
sub _make_predictor_operations {
    my ($self, $workflow) = @_;
    my @predictors = $self->_get_or_create_parser->predictor_classes;
    my @predictor_operations;
    for my $predictor (@predictors) {
        my $predictor_operation = Genome::WorkflowBuilder::Command->create(
            name => $predictor->class_to_short_name,
            command => $predictor,
            ($predictor->requires_chunking ? (parallel_by => 'input_fasta_file') : () ),
        );
        $workflow->add_operation($predictor_operation);
        push @predictor_operations, $predictor_operation;
    }
    return @predictor_operations;
}

# Links the input connector and fasta chunk operation to the predictor operations
sub _link_inputs_to_predictors {
    my $self = shift;
    my %params = @_;
    my $workflow = delete $params{workflow};
    die "Require workflow!" unless $workflow;
    my @predictor_operations = @{delete $params{predictor_operations}};
    die "Require predictor operations!" unless @predictor_operations;

    my $fasta_chunk_operation = delete $params{fasta_chunk_operation};
    my @predictors = $self->_get_or_create_parser->predictor_classes;
    if ((grep { $_->requires_chunking } @predictors) and !$fasta_chunk_operation) {
        die "No fasta chunk operation provided, but at least one predictor requires chunking!";
    }
    
    my %input_mapping = $self->_gather_properties_of_type('input', @predictors);
    for my $predictor_operation (@predictor_operations) {
        my $predictor = $predictor_operation->command;
        my @predictor_inputs = @{$input_mapping{$predictor}};
        my $predictor_name = $predictor->class_to_short_name;
        for my $input (@predictor_inputs) {
            if ($input =~ /input_fasta_file/ and $predictor->requires_chunking) {
                $workflow->create_link(
                    source => $fasta_chunk_operation,
                    source_property => 'fasta_files',
                    destination => $predictor_operation,
                    destination_property => 'input_fasta_file',
                );
            }
            # For predictor specific inputs, need to strip out the leading predictor name
            # so link works. For example, interproscan_version needs to link with version.
            elsif ($input =~ /^$predictor_name/) {
                my $actual_input = $input;
                my $string_to_remove = $predictor_name . '_';
                $actual_input =~ s/$string_to_remove//;
                $workflow->connect_input(
                    input_property => $input,
                    destination => $predictor_operation,
                    destination_property => $actual_input,
                );
            }
            else {
                $workflow->connect_input(
                    input_property => $input,
                    destination => $predictor_operation,
                    destination_property => $input,
                );
            }
        }
    }

    return 1;
}

# Links the predictors with the converge step and output connector.
sub _create_converge_and_link_to_predictors {
    my $self = shift;
    my %params = @_;
    my $workflow = delete $params{workflow};
    die "Require workflow!" unless $workflow;
    my @predictor_operations = @{delete $params{predictor_operations}};
    die "Require predictor operations!" unless @predictor_operations;

    my @predictors = $self->_get_or_create_parser->predictor_classes;
    my %output_mapping = $self->_gather_properties_of_type('output');
    my %predictor_converge_mapping;

    for my $predictor (@predictors) {
        my ($output) = grep { $_ eq 'bio_seq_features' } @{$output_mapping{$predictor}};
        $predictor_converge_mapping{$predictor} = [$output, join('_', $predictor->class_to_short_name, $output)];
    }

    my $converge_operation = Genome::WorkflowBuilder::Converge->create(
        name => 'converge',
        input_properties => [map { $predictor_converge_mapping{$_}->[1] } sort keys %predictor_converge_mapping],
        output_properties => ['features'],
    );
    $workflow->add_operation($converge_operation);

    for my $predictor_operation (@predictor_operations) {
        my $predictor = $predictor_operation->command;
        $workflow->create_link(
            source => $predictor_operation,
            source_property => $predictor_converge_mapping{$predictor}->[0],
            destination => $converge_operation,
            destination_property => $predictor_converge_mapping{$predictor}->[1],
        );
    }

    $workflow->connect_output(
        source => $converge_operation,
        source_property => 'features',
        output_property => 'bio_seq_features',
    );

    return $converge_operation;
}

sub _create_merge_ace_file_operation {
    my $self = shift;
    my %params = @_;
    my $workflow = delete $params{workflow};
    die "Require workflow!" unless $workflow;
    my @predictor_operations = @{delete $params{predictor_operations}};
    die "Require predictor operations!" unless @predictor_operations;

    my $merge_operation;
    my @predictors = grep { $_->can('requires_chunking') and $_->requires_chunking } $self->_get_or_create_parser->predictor_classes;
    if (@predictors) {
        for my $predictor (@predictors) {
            my ($operation) = grep { $_->name eq $predictor->class_to_short_name } @predictor_operations;
            
            $merge_operation = Genome::WorkflowBuilder::Command->create(
                name => 'merge_ace_files',
                command => 'Genome::Model::Tools::MergeFiles',
            );
            $workflow->add_operation($merge_operation);

            $workflow->create_link(
                source => $operation,
                source_property => 'ace_file',
                destination => $merge_operation,
                destination_property => 'input_files',
            );

            $workflow->connect_input(
                input_property => join('_', $predictor->class_to_short_name, 'output_directory'),
                destination => $merge_operation,
                destination_property => 'output_directory',
            );

            $workflow->connect_output(
                source => $merge_operation,
                source_property => 'result',
                output_property => 'result',
            );
        }
    }

    return $merge_operation;
}

1;

